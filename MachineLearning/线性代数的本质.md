# 线性代数的本质

## 向量

​		要理解向量，首先要思考一个问题，也就是如何去定义一个点？回想我们在日常生活中对物体的定义，比如一个苹果，我们对它的定义是通过分辨出它不是香蕉，不是梨，不是橘子来实现的，也就是寻找到苹果与其它物体的差异。对于一个点的定义，我们也是采用这种方式来实现的，也就是找到这个点与其他点的差异，这个差异我们就用向量来表示。

​		我们可以用不同的特征来表示两个点的差异，因此就会有不同的维度。在一维时，向量实际上就是标量，两个点之间的差异（距离）用数值的大小表示，方向用正负号表示；在二维时，向量就是一个有序数对，以此类推。

​		向量的计算方式就是加法和数乘，这两种计算方式实际上是同质的，都是加法，因为加法代表的就是一个增量$ \Delta$，也就是差异，而向量通过使用加法和数乘法则所张成的空间也就是线性空间，这个空间实际上蕴含了这么一个假设：每个点的内部性都是被消解的，其内部差异被抹除，因此点的定义，点与点之间的关系都需要通过一个外部公共的空间来确定，每个点都需要通过他者来确证自身；而采用不同的空间就会产生不同的定义和关系。

​		刚才我们的视点是从固定的外部公共空间出发来看待的，但我们也可以反过来：因为每个点都不具有内部性，所以我们可以将每个点都看成是同一个点，而点与点之间的差异是由这个外部空间的变换造成的。比如在以$ v_1=(1,0),v_2=(0,1)$为基向量所张成的空间中的点$ a=(3,1)$来说，它与另一个点$ b=(3,2)$的关系就是：b点实际上是a点从原空间转到另一个以$ u_1=(1,0),u_2=(1,1)$为基向量所张成的空间中的点。这个过程就是所谓的线性变换：
$$
\begin{bmatrix}
1 & 1\\
0 & 1\\
\end{bmatrix}
\cdot
\begin{bmatrix}
3\\
1\\
\end{bmatrix}

=
\begin{bmatrix}
3\\
2\\
\end{bmatrix}
$$

## 从点到矩阵

​		虽然说孤立的点不具有内部性，但点与点之间有不同的差异和关系，这些关系就可以构建起结构，所以如果我们将一群点$ x_i$聚为一类，用矩阵$ X=\{x_1,x_2,\cdots,x_n\}$表示，那么该矩阵就具有了内部性，在统计角度上我们将其称为分布，通常用均值和方差来作为表征，这一内部性也是为什么矩阵乘法有顺序的原因。

​		知道这一点之后，我们也可以从信息的角度来看刚才的线性变换。一个矩阵静态地看就是其中每个点位关系的信息总和，动态地看就是对信息进行加工处理的过程，比如说行列式在几何上表征的是对空间的压缩或扩张，小于1时是压缩大于1时是扩张，即代表对信息的加工处理。而矩阵的秩在几何上表征的是空间的维度，但也可以看成是对信息的压缩程度，但如果将一个矩阵从低维映射到高维，不代表该矩阵信息增加了，因为它内部点的相对关系没有改变，所以信息量不变，当然，如果是非线性变换的话，就可能会引入新的信息。