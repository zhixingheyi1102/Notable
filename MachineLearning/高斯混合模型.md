# 高斯混合模型

## 模型理解

​		高斯混合模型中的高斯是指高斯分布，混合是指有多个高斯分布混合在一起，比如图1-1中，有两个高斯分布，这是一组一维数据，纵轴表示概率，此图也是概率密度函数图。其中蓝色的曲线代表每一个高斯分布的概率密度，红色曲线代表两个高斯模型叠加而成的混合概率密度。

![img](https://pic1.zhimg.com/80/v2-0b7dbf6d3e80dc8e11d7e188e4db627c_720w.webp)

​		对于该模型，可以从以下两个角度进行理解：

### 几何角度

​		将该分布视为多个高斯分布的加权叠加，因此叠加后可得到其概率分布为：
$$
P(x)=\Sigma_ {k=1}^K\alpha_kN(\mu_k,\Sigma_k),\Sigma_ {k=1}^K\alpha_k=1
$$

### 生成模型角度

​		之所以将GMM、HMM这类模型称为生成模型是因为这类模型能够对联合概率分布进行建模，它可以从数据集中学习到数据的统计规律，进而可以生成与原始数据相似的新样本。生成模型通常涉及到对变量之间的条件依赖关系进行建模，其中隐变量是重要的组成部分，因为隐变量可以帮助模型更好地捕捉数据的复杂性和变异性。

​		因此，我们需要定义隐变量$z$，其对应的是样本x属于哪一个高斯分布，每一个样本点$x_i$对应一个隐变量$z_i$，因此我们将$(x,z)$称为完整数据，隐变量$z$定义如下：

![image-20230222225126321](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230222225126321.png)

​		实际上从该角度得到的概率密度于几何角度的结果相同，也就是说我们既可以把样本点视作属于其中一个高斯分布，也可以视作是多个高斯分布的加权。

![image-20230222225742123](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230222225742123.png)

## EM求解

​		对于GMM模型来说，直接用MLE求解，无法得出解析解（得到式子形式为log连加，无法化简）。对于无法求出解析解的情况，一般使用数值解法，如梯度下降的方法，但是对于GMM含有隐变量的问题，使用EM算法将是更优的选择。

​		使用EM算法求解GMM模型参数的步骤如下：

### 初始化参数

​		初始化参数。随机初始化高斯分布的均值、方差和混合系数。

### E-step

​	EM算法：

![image-20230222225943080](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230222225943080.png)



### M-step

![image-20230222225901127](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230222225901127.png)

### 迭代直到收敛

​		重复执行E步骤和M步骤，直到收敛为止。具体来说，可以定义一个收敛条件，比如似然函数的变化量小于某个阈值，或者迭代次数达到预设值。

然后输出估计的模型参数。经过多轮迭代后，EM算法会得到GMM模型的参数估计，包括每个高斯分布的均值、协方差矩阵和混合系数。

### 注意事项

1. 初始化参数的选择对算法的结果有很大的影响。一般情况下，可以采用随机初始化或者K-means算法的结果作为初始值。
2. 在E步骤中，需要计算样本来自每个高斯分布的概率。如果样本数量很大，计算量会很大，因此可以使用矩阵计算加速。
3. 在M步骤中，需要重新估计高斯分布的参数。由于每个高斯分布都需要计算均值、方差和混合系数，因此计算量也很大。在实现时，可以采用向量化计算或者GPU加速等方法来提高计算效率。
4. 由于EM算法只能得到局部最优解，因此需要多次随机初始化，并选择似然函数最大的一组参数作为最终结果

