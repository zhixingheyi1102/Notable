# 概率论

核心问题是如何用数学的方式来描述不确定性

## 概率论的发生学

### 1.0

### 2.0

### 3.0

## 层次

### 概率空间

​		因为任意一个样本空间都可以对应到一个实数空间上，我们可以将这个概率空间视为一个实数空间，只不过多了一个修饰项$P(e)$,表示该空间中某个线段的取值（质量）；而在实际应用中，为了计算方便，我们使用累积分布$F(x)$来进行表示，其导数$f(x)$就是密度函数，实际上就是给该实数空间中的每一个点都赋予了一个权重。![image-20230111111011584](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230111111011584.png)

### 升维

​		考虑一个二维的密度函数 ，其实际上是一个在二维平面上的场，其中每个点都代表两个随机变量的联合概率密度：

![image-20230111112057670](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230111112057670.png)

​		而边缘概率，代表的是该二维平面在其中一个随机变量上的投影，如$X_2$轴上的每一个点，实际上代表的是二维平面平面上垂直于该点的直线的质量：

![image-20230111112724425](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230111112724425.png)![image-20230111112738250](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230111112738250.png)

​		条件概率代表的是对该平面内某条平行于坐标轴的直线的归一化表示：

![image-20230111113104913](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230111113104913.png)

### 对P的描述

#### P的无损描述（概率论）

​		P的无损描述，指的就是用累积分布函数（CDF）来描述该概率分布，而通过累积分布函数也可以相应地求出概率密度函数（PDF）和概率质量函数（PMF）。

​		概率论的一个研究方向是，通过随机变量的变换关系，从已知的随机变量的概率分布，推出另一个随机变量的概率分布。通过这种方式，可以较方便地求出一些比较复杂的概率分布。如有两个随机变量X、Y，二者满足二次函数关系，实际上就是将随机变量X的那条实数轴掰成二次函数，而Y的概率质量就是该区间质量的和：

![image-20230111114451824](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230111114451824.png)

#### P的参数特征（数理统计）

​		对于P这一概率分布的描述，我们也可以通过能表示该分布的参数特征来描述，比如方差和期望。因此数理统计的一个研究方向就是如何确定该数据集的分布及其参数特征。

​		对于分布来说，可以分为简单分布和复杂分布，对于简单分布来说，通常是通过经验和实践来确定适用的分布，而对于复杂分布来说，一种方式是通过似然函数，并通过样本来确定似然函数的参数来逼近原函数：

![image-20230112223335277](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230112223335277.png)

​		另一个方式是将复杂分布视作是简单分布的叠加：其中H变量也被称为隐变量，该变量对原分布进行拆解，变为几个简单分布

![image-20230112223441125](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230112223441125.png)

​		对于参数特征来说，可以通过抽样样本来构建统计量，然后通过该统计量来求取特征。比如对于参数特征均值和方差来说，我们可以通过构建统计量$\bar{X}$来进行求取，过程如下所示：

![image-20230112215711564](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230112215711564.png)

​		而由于统计量是从样本中归纳得出的，因此其没有办法真正地确定参数特征，只能是对其进行评估，对概率空间进行估计，而大数定律、中心极限定理就可以对部分统计量的靠谱程度提供数理基础：比如对于$\bar{X}$来说，根据大数定律，进行采样的次数越多，$\bar{X}$的质量也就约接近均值$\mu$,评估效果越好

![image-20230112220854516](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230112220854516.png)

​		而根据中心极限定理，不管是什么样的分布，只要存在期望和方差，当采样次数足够大时，其统计量$\bar{X}$一定服从正态分布，并可以通过求出该正态分布的方差和期望来反推原分布的方差和期望

![image-20230112221256222](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230112221256222.png)



#### P的整体特征（信息论）

​		除此之外，我们还可以用熵来描述P的整体特征，即其形状，我们可以对比一下期望和熵这两个量，期望与x有关，因此与该概率分布的位置信息有关，而熵只与$p(x)$有关，因此可以用来描述概率分布的形状特征，实际上是表示该概率分布的混乱程度，熵越大该分布扯得越平，熵越小该分布越集中：

![image-20230112224321430](C:\Users\Go\AppData\Roaming\Typora\typora-user-images\image-20230112224321430.png)







